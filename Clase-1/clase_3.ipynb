{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) ForwardPropagation (Propagacion hacia delante)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este erjercicio generaremos una propagacion hacia delante y posteriormente \n",
    "una propagacion hacia atras dentro de lamisma red de neuronas que se definira \n",
    "<!-- a continuacion. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como paso preliminar preparamos el entorno donde trabajaremos\n",
    "\n",
    "-   Instalamos las libreras que nos falten, en este caso faltaba por instalar PANDAS.\n",
    "-   Importamos las librerias que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  #para el BackPropagation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Se define una red neuronal con las siguientes caracteristicas\n",
    "\n",
    "-   1.- Una capa de entrada con dos inputs, x1 y x2.\n",
    "-   2.- Una capa oculta con 4 neronas h1, h2 , h3 y h4.\n",
    "-   3.-una capa de salida con 1 neurona o1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Inicializamos los pesos de las 4 neuronas de la capa oculta y los visualisamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2  0.65 0.45 0.12]\n",
      " [0.8  0.35 0.55 0.15]]\n"
     ]
    }
   ],
   "source": [
    "Wxh=np.array([[0.2,0.65,0.45,0.12],\n",
    "              [0.8,0.35,0.55,0.15],\n",
    "              ]) # X1 [1x4] y X2 [1x4]\n",
    "print(Wxh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Inicializamos los pesos de las neuronas de la capa de salida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 ]\n",
      " [0.35]\n",
      " [0.45]\n",
      " [0.52]]\n"
     ]
    }
   ],
   "source": [
    "#pesos de la neirona de la capa de salida\n",
    "\n",
    "Why=np.array([[0.2],\n",
    "              [0.35],\n",
    "              [0.45],\n",
    "              [0.52],\n",
    "              ]) #Xo1 [4x1]\n",
    "print(Why)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Inicializamos los sesgos de la neuronas de la capa oculta Z1 y de la capa de salida Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.15 0.45 0.23] 0.05\n"
     ]
    }
   ],
   "source": [
    "bh=np.array([0.2,0.15,0.45,0.23]) #bh [1x4]\n",
    "by=0.05 #by [1x4]\n",
    "print(bh,by)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Definimos la funcion de activacion como la sigmoide o logistic (logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  s=  1/(1+np.exp(-x))\n",
    "  return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Definimos la propagacion hacia delante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x):\n",
    "    global z1, z2\n",
    "    z1=np.dot(x,Wxh)+bh     #capa oculta -----(1x2)(2x4)=(1x4)+(1x4)\n",
    "    a1=sigmoid(z1)          #capa oculta -----(1x4)\n",
    "    z2=np.dot(a1,Why)+by    #capa salida -----(1x4)(4x1)=(1x1)\n",
    "    y_gorro=sigmoid(z2)     #capa salida -----(1x4)\n",
    "    return y_gorro          #salida -----(1x1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Definimos el vector de impulso para estimar y_Gorro (como prueba de la propagacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8277821])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=np.array([1.75,70])\n",
    "#y_gorro = forward_prop(x)\n",
    "#y_gorro "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Backpropagation (propagacion hacia atras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Definicion de la derivada de la sigmoide Prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidPrime(x):\n",
    " d  =  np.exp(-x)/((1+np.exp(-x))**2)\n",
    " return d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Preparamos la BackPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backword_prop(y_gorro, z1, a1, z2, alpha):\n",
    "    global Wxh, Why, dJ_dWxh\n",
    "    delta2 = np.multiply(-(y-y_gorro), sigmoidPrime(z2))  # --> 1x1 X 1x1 = 1x1\n",
    "    dJ_dWhy = np.dot(a1.reshape(4,1), delta2) # --> 4x1.T * 1x1 = 4x1\n",
    "    delta1 = np.dot(delta2,Why.T)*sigmoidPrime(z1)  # --> 1x1 * 1x4.T * 1 = 1x4\n",
    "    dJ_dWxh = np.dot(x.reshape(2,1), delta1.reshape(1,4))  # --> 2x1 * 1x4 =2x4\n",
    "    Wxh = Wxh - alpha * dJ_dWxh.T # -->2x4 -alpha * 4x2 = 2x2\n",
    "    Why = Why - alpha * dJ_dWhy.reshape(1,8)  #4x1-alpha *  1x8.T = \n",
    "    return Wxh, Why"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Recalculo de parametros empleando BackPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.6,65.8])\n",
    "y_gorro = forward_prop(x)\n",
    "z1 = np.dot(x,Wxh) + bh\n",
    "a1 = sigmoid(z1)\n",
    "z2 = np.dot(a1,Why) + by\n",
    "alpha = 0.025\n",
    "y = 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (8,) not aligned: 1 (dim 1) != 8 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[218], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m backword_prop(y_gorro, z1, a1, z2,alpha)\n",
      "Cell \u001b[1;32mIn[216], line 4\u001b[0m, in \u001b[0;36mbackword_prop\u001b[1;34m(y_gorro, z1, a1, z2, alpha)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mglobal\u001b[39;00m Wxh, Why, dJ_dWxh\n\u001b[0;32m      3\u001b[0m delta2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(\u001b[39m-\u001b[39m(y\u001b[39m-\u001b[39my_gorro), sigmoidPrime(z2))  \u001b[39m# --> 1x1 X 1x1 = 1x1\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dJ_dWhy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(a1\u001b[39m.\u001b[39;49mreshape(\u001b[39m4\u001b[39;49m,\u001b[39m1\u001b[39;49m), delta2) \u001b[39m# --> 4x1.T * 1x1 = 4x1\u001b[39;00m\n\u001b[0;32m      5\u001b[0m delta1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(delta2,Why\u001b[39m.\u001b[39mT)\u001b[39m*\u001b[39msigmoidPrime(z1)  \u001b[39m# --> 1x1 * 1x4.T * 1 = 1x4\u001b[39;00m\n\u001b[0;32m      6\u001b[0m dJ_dWxh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(x\u001b[39m.\u001b[39mreshape(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m), delta1\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m4\u001b[39m))  \u001b[39m# --> 2x1 * 1x4 =2x4\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,1) and (8,) not aligned: 1 (dim 1) != 8 (dim 0)"
     ]
    }
   ],
   "source": [
    "backword_prop(y_gorro, z1, a1, z2,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Definir fución de predicción.\n",
    "\n",
    "def pred(X):\n",
    " z1 = np.dot(X,Wxh) + bh\n",
    " a1 = sigmoid(z1)\n",
    " z2 = np.dot(a1,Why) + by\n",
    " y_hat = sigmoid(z2)\n",
    " return y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
